import os
import yaml
import tensorflow as tf

from components.data_preprocessing import DataPreprocessing
from model.data_utils import VectorizeChar
from model.model import Transformer
from model.utils import CustomSchedule, DisplayOutputs

class SpeechTrainer:
    def __init__(self, config_path="./configs/config.yaml"):
        """
        åˆå§‹åŒ– SpeechTrainerï¼Œå¾ YAML è¨­å®šæª”è®€å–åƒæ•¸ã€‚
        """
        self.config = self.load_config(config_path)

        # ====== è®€å–æ•¸æ“šç›¸é—œè¨­å®š ======
        # æ”¹ç”¨ DataPreprocessing ä¾†ä¸€æ¬¡æ€§è™•ç†éŸ³è¨Š
        self.tsv_path = self.config["data"]["tsv_path"]
        self.audio_folder = self.config["data"]["audio_folder"]
        self.test_size = self.config["data"]["test_size"]
        self.max_target_len = self.config["data"]["max_target_len"]

        # ====== è®€å–è¨“ç·´ç›¸é—œè¨­å®š ======
        self.batch_size = self.config["training"]["batch_size"]
        self.val_batch_size = self.config["training"]["val_batch_size"]
        self.epochs = self.config["training"]["epochs"]
        self.num_classes = self.config["training"]["num_classes"]

        # ====== è®€å–æ¨¡å‹è¶…åƒæ•¸ ======
        self.model_params = self.config["model"]

        # ====== åˆå§‹åŒ–è®Šæ•¸ ======
        self.vectorizer = None
        self.train_dataset = None
        self.val_dataset = None
        self.model = None

    def load_config(self, config_path):
        """
        è®€å– YAML è¨­å®šæª”
        """
        with open(config_path, "r", encoding="utf-8") as file:
            return yaml.safe_load(file)

    def prepare_data(self):
        """
        ä½¿ç”¨ data_preprocessing.py ä¸­çš„é›¢ç·šè™•ç†æ–¹æ³•:
         1. ä¸€æ¬¡æ€§è™•ç†æ‰€æœ‰éŸ³æª” => å¾—åˆ° dataList (å« spectrogram)
         2. åˆ‡åˆ† train / val
         3. å»ºç«‹ vectorizer
         4. ç”¢ç”Ÿ train_ds / val_ds
        """
        print("è¼‰å…¥ & ä¸¦è¡Œè™•ç†éŸ³æª”ï¼Œç„¶å¾Œåˆ‡åˆ†è³‡æ–™é›†...")
        dp = DataPreprocessing(self.config)

        # 1) å…¨éƒ¨éŸ³æª”é›¢ç·šè™•ç† => data[i]["spectrogram"]
        data = dp.preprocess_all_audio()

        # 2) åˆ‡åˆ†æˆ train / val
        train_data, val_data = dp.split_data(data)

        # 3) å»ºç«‹æ–‡å­—å‘é‡åŒ–å™¨(åªç”¨ train_data çš„å¥å­ä¾†å»º)
        self.vectorizer = dp.build_vectorizer(train_data)

        # 4) åˆ†åˆ¥åš train_dataset / val_dataset
        self.train_dataset = dp.to_tf_dataset(train_data, self.vectorizer, self.batch_size)
        self.val_dataset = dp.to_tf_dataset(val_data, self.vectorizer, self.val_batch_size)

        print(f"è³‡æ–™é›†è™•ç†å®Œæˆï¼")
        print(f" - è¨“ç·´æ•¸æ“š: {len(train_data)} ç­†")
        print(f" - é©—è­‰æ•¸æ“š: {len(val_data)} ç­†")
        print(f" - å­—å…¸å¤§å°: {len(self.vectorizer.get_vocabulary())}")

    def initialize_model(self):
        """
        åˆå§‹åŒ– Transformer æ¨¡å‹
        """
        print("ğŸ”¹ åˆå§‹åŒ– Transformer æ¨¡å‹...")
        self.model = Transformer(
            num_hid=self.model_params["num_hid"],
            num_head=self.model_params["num_head"],
            num_feed_forward=self.model_params["num_feed_forward"],
            target_maxlen=self.max_target_len,
            num_layers_enc=self.model_params["num_layers_enc"],
            num_layers_dec=self.model_params["num_layers_dec"],
            num_classes=self.num_classes,
        )
        print("æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼")

    def train_model(self):
        """
        è¨“ç·´æ¨¡å‹
        """
        print("é–‹å§‹è¨“ç·´...")
        loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)

        # è¨­å®šå­¸ç¿’ç‡æ’ç¨‹
        steps_per_epoch = len(self.train_dataset)
        learning_rate = CustomSchedule(
            init_lr=0.00001,
            lr_after_warmup=0.001,
            final_lr=0.00001,
            warmup_epochs=15,
            decay_epochs=40,
            steps_per_epoch=steps_per_epoch,
        )
        optimizer = tf.keras.optimizers.Adam(learning_rate)

        # ç·¨è­¯æ¨¡å‹
        self.model.compile(optimizer=optimizer, loss=loss_fn)

        # è¨­ç½® Callbacks
        # é€™è£¡å…ˆå¾ train_dataset å–ä¸€å€‹ batchï¼Œç”¨æ–¼ DisplayOutputs
        first_batch = next(iter(self.train_dataset))
        display_cb = DisplayOutputs(
            first_batch,
            self.vectorizer.get_vocabulary(),
            target_start_token_idx=2,
            target_end_token_idx=3
        )
        early_stopping = tf.keras.callbacks.EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True)

        # é–‹å§‹ fit
        self.model.fit(
            self.train_dataset,
            validation_data=self.val_dataset,
            epochs=self.epochs,
            callbacks=[display_cb, early_stopping],
        )
        print("è¨“ç·´å®Œæˆï¼")

    def save_model(self, save_path="checkpoints/final_model.h5"):
        """
        å„²å­˜æ¨¡å‹
        """
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        self.model.save(save_path)
        print(f"æ¨¡å‹å·²å„²å­˜è‡³ {save_path}")

    def run(self):
        """
        åŸ·è¡Œå®Œæ•´æµç¨‹:
          1) é›¢ç·šä¸¦è¡Œè™•ç†æ‰€æœ‰éŸ³æª” + åˆ‡åˆ† + å»ºç«‹ Dataset
          2) åˆå§‹åŒ–æ¨¡å‹
          3) è¨“ç·´
          4) å„²å­˜æ¨¡å‹
        """
        self.prepare_data()
        # self.initialize_model()
        # self.train_model()
        # self.save_model()

def main():
    trainer = SpeechTrainer(config_path="./configs/config.yaml")
    trainer.run()  # åŸ·è¡Œå®Œæ•´çš„è¨“ç·´æµç¨‹

if __name__ == "__main__":
    main()
